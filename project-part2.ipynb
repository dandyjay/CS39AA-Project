{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4840139,"sourceType":"datasetVersion","datasetId":2805070}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-28T02:24:20.478677Z","iopub.execute_input":"2023-11-28T02:24:20.479296Z","iopub.status.idle":"2023-11-28T02:24:20.488947Z","shell.execute_reply.started":"2023-11-28T02:24:20.479249Z","shell.execute_reply":"2023-11-28T02:24:20.487860Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"/kaggle/input/genius-song-lyrics-with-language-information/song_lyrics.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"lyric_database = pd.read_csv(\"/kaggle/input/genius-song-lyrics-with-language-information/song_lyrics.csv\")\nlyric_database.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T02:24:20.490762Z","iopub.execute_input":"2023-11-28T02:24:20.491111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"db = lyric_database.sample(frac=0.01, random_state=1) #this database has 3 million entries\ndb = (\n    db\n    .loc[db[\"language\"] == \"en\"]\n    .loc[db[\"tag\"] != \"misc\"]\n    .loc[db[\"tag\"] != \"\"]\n    .loc[db[\"tag\"] != None]\n    .loc[db[\"lyrics\"] != None]\n    .loc[db[\"lyrics\"] != \"\"]\n    .loc[db[\"lyrics\"] != \"[Instrumental]\"]\n)\ncolumns_of_interest = ['id', 'title','artist', 'lyrics', 'tag']\ndb = db[columns_of_interest]\ndb = db.sort_values(by=\"id\")\ndb.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(db.tag.unique())\nprint(db.tag.value_counts(normalize=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport nltk\n\ndef fix_lyrics(lyrics):\n    parts = re.split(r\"([\\n\\[\\]\\(\\)])\", lyrics)\n    output = \" \".join(filter(None, parts))\n    output = re.sub(r\"([?.,!:;])\",'',output)\n    output = re.sub(r\"in'(?= \\w|\\.|,|$)\",\"ing\",output.lower())\n    return output\n\n\ndb[\"lyrics\"] = db[\"lyrics\"].apply(fix_lyrics)\ndb = db.sort_values(by=\"id\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\ndb['tokens_raw'] = db['lyrics'].apply(lambda x: word_tokenize(x.lower()))\ndb.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nstopwords = nltk.corpus.stopwords.words('english')\ndb['tokens_raw'] = db['tokens_raw'].apply(lambda x: [w for w in x if w not in stopwords])\ndb['lyrics_clean'] = db['tokens_raw'].apply(lambda x: ' '.join(x))\n\ndb.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = db['lyrics_clean'].copy()\ny = db['tag'].copy()\n\nX_train_raw, X_val_raw, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=60)\nprint(X_train_raw)\nprint(y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n#import seaborn as sns\n\n#tfidf_vectorizer = TfidfVectorizer()\n#X_train = tfidf_vectorizer.fit_transform(X_train_raw).toarray()\n\n# an alternative is to use term frequency:\nfrom sklearn.feature_extraction.text import CountVectorizer\none_hot_vectorizer = CountVectorizer(binary=True)\nX_train = one_hot_vectorizer.fit_transform(X_train_raw)\n\nprint(f\"X_train.shape = {X_train.shape}\")\ntype(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_val = one_hot_vectorizer.transform(X_val_raw).toarray()\nprint(f\"X_val.shape = {X_val.shape}\")\ntype(X_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"pop songs = {len(db.loc[db['tag'] == 'pop'])}\")\nprint(f\"rap songs = {len(db.loc[db['tag'] == 'rap'])}\")\nprint(f\"rock songs = {len(db.loc[db['tag'] == 'rock'])}\")\nprint(f\"rb songs = {len(db.loc[db['tag'] == 'rb'])}\")\nprint(f\"country songs = {len(db.loc[db['tag'] == 'country'])}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n\n\nmodels = []\nfor i in range(1,10):\n    model = KNeighborsClassifier(n_neighbors=i)\n    model = model.fit(X_train, y_train)\n\n    predictions_train = model.predict(X_train)\n\n    disp = ConfusionMatrixDisplay(confusion_matrix(y_train, predictions_train), display_labels=['pop','rap','rock','rb','country'])\n    disp.plot()\n    print(f\"accuracy ({i}): {accuracy_score(y_train, predictions_train):.4f}\")\n    models.append(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import log_loss\n\n# A function to create and fit a RF with a specific number of trees\ndef tuneModel(hyperparam_value):\n    rf_model = KNeighborsClassifier(n_neighbors=hyperparam_value) \n    #rf_model = RandomForestClassifier(min_samples_split=hyperparam_value, random_state=1)\n    rf_model.fit(X_train, y_train)\n    y_train_pred_prob = rf_model.predict_proba(X_train)\n    y_train_pred = rf_model.predict(X_train)\n    y_val_pred_prob = rf_model.predict_proba(X_val)\n    y_val_pred = rf_model.predict(X_val)\n    train_loss = log_loss(y_train, y_train_pred_prob, labels=['pop', 'rap', 'rock', 'rb', 'country'])\n    train_acc = accuracy_score(y_train, y_train_pred)\n    val_loss = log_loss(y_val, y_val_pred_prob, labels=['pop', 'rap', 'rock', 'rb', 'country'])\n    val_acc = accuracy_score(y_val, y_val_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix(y_train, predictions_train), display_labels=['pop','rap','rock','rb','country'])\n    disp.plot()\n    print(f\"accuracy ({hyperparam_value}): {val_acc}\")\n    return (train_loss, val_loss, train_acc, val_acc)\n\n# Possible values for the hyperparameter are in the range of 5 to 150 (by 50)\nhyp_param_vals = range(1,10) # good values for n_estimators\n#hyp_param_vals = [2,3] + list(range(5, 50, 10)) # good values for min_samples_split\nmetrics = []\n\nfor hp in hyp_param_vals:\n    metrics.append(tuneModel(hp))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig = plt.figure(figsize=(12, 6))\nax = fig.add_axes([0, 0, 1, 1]) #.1, 0.1, 0.8, 0.8]) # main axes\nax.plot(hyp_param_vals, [metric[1] for metric in metrics], '--ro') # validattion loss\nax.plot(hyp_param_vals, [metric[0] for metric in metrics], '--bo') # training loss\nax.legend([\"Validation Loss\", \"Train Loss\"], loc=1)\nax.set_xticks(hyp_param_vals)\nax.set(xlabel=\"n_estimators\", ylabel=\"loss (lower is better)\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12, 6))\nax = fig.add_axes([0, 0, 1, 1]) #.1, 0.1, 0.8, 0.8]) # main axes\nax.plot(hyp_param_vals, [metric[3] for metric in metrics], '--ro') # validattion accuracy\nax.plot(hyp_param_vals, [metric[2] for metric in metrics], '--bo') # training accuracy\nax.legend([\"Validation Accuracy\", \"Train Accuracy\"], loc=4)\nax.set_xticks(hyp_param_vals)\nax.set(xlabel=\"n_estimators\", ylabel=\"accuracy (higher is better)\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}